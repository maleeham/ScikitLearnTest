{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-4e25ee396bc7>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/tarrysingh/.local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/tarrysingh/.local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/tarrysingh/.local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/tarrysingh/.local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/tarrysingh/.local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are we going to do\n",
    "\n",
    "We are going to pretend as if we have a sophisticated NN (without CNN brain)\n",
    "1. Hyperparameters\n",
    "2. Network Parameters\n",
    "3. TF Graph Input\n",
    "4. MLP Model\n",
    "5. Weights, Biases, Cost , Optimizer\n",
    "6. Running and evaluating the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate   = 0.001\n",
    "training_epochs = 100\n",
    "batch_size      = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Parameters\n",
    "n_hidden_1 = 256\n",
    "n_hidden_2 = 256\n",
    "n_input    = 784\n",
    "n_classes  = 10\n",
    "n_samples  = mnist.train.num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF Graph Input\n",
    "x = tf.placeholder(\"float\", [None, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi Layer Perceptron Model\n",
    "def multilayer_perceptron(x, weights, biases):\n",
    "    '''\n",
    "    Add explanation\n",
    "    \n",
    "    '''\n",
    "    # First hidden layer with RELU activation function\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    \n",
    "    # Second layer\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    \n",
    "    # Final output\n",
    "    \n",
    "    out_layer = tf.add(tf.matmul(layer_2, weights['out']), biases['out'])\n",
    "    return out_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights and biases\n",
    "\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out':tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "biases = {\n",
    "    'b1':tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2':tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out':tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction label\n",
    "pred = multilayer_perceptron(x, weights, biases )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost/Loss and Optimizer Functions\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels= pred, logits=y))\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize global variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 cost=-6235522.8330\n",
      "Epoch: 2 cost=-76879479.9891\n",
      "Epoch: 3 cost=-309665839.1855\n",
      "Epoch: 4 cost=-801715683.8982\n",
      "Epoch: 5 cost=-1651904879.2436\n",
      "Epoch: 6 cost=-2955200278.3418\n",
      "Epoch: 7 cost=-4811483886.7782\n",
      "Epoch: 8 cost=-7319775366.0509\n",
      "Epoch: 9 cost=-10570859302.1673\n",
      "Epoch: 10 cost=-14669954943.5345\n",
      "Epoch: 11 cost=-19704875579.5782\n",
      "Epoch: 12 cost=-25777180180.4800\n",
      "Epoch: 13 cost=-32991189900.5672\n",
      "Epoch: 14 cost=-41437791384.6691\n",
      "Epoch: 15 cost=-51215646362.5310\n",
      "Epoch: 16 cost=-62427445895.9127\n",
      "Epoch: 17 cost=-75162202558.8362\n",
      "Epoch: 18 cost=-89508013864.0292\n",
      "Epoch: 19 cost=-105589330083.8400\n",
      "Epoch: 20 cost=-123487733141.8764\n",
      "Epoch: 21 cost=-143288720812.2180\n",
      "Epoch: 22 cost=-165107338176.6980\n",
      "Epoch: 23 cost=-189037670027.6362\n",
      "Epoch: 24 cost=-215182086009.9490\n",
      "Epoch: 25 cost=-243609886302.9527\n",
      "Epoch: 26 cost=-274452766005.0621\n",
      "Epoch: 27 cost=-307804857064.7275\n",
      "Epoch: 28 cost=-343726960922.9966\n",
      "Epoch: 29 cost=-382375003720.6111\n",
      "Epoch: 30 cost=-423771542472.1457\n",
      "Epoch: 31 cost=-468083073589.9927\n",
      "Epoch: 32 cost=-515347698334.2551\n",
      "Epoch: 33 cost=-565756989871.9418\n",
      "Epoch: 34 cost=-619321887293.4407\n",
      "Epoch: 35 cost=-676100205802.5889\n",
      "Epoch: 36 cost=-736307397382.5172\n",
      "Epoch: 37 cost=-799946375048.8439\n",
      "Epoch: 38 cost=-867220085681.8036\n",
      "Epoch: 39 cost=-938082952091.4619\n",
      "Epoch: 40 cost=-1012777188422.7494\n",
      "Epoch: 41 cost=-1091226656261.5853\n",
      "Epoch: 42 cost=-1173760170334.0215\n",
      "Epoch: 43 cost=-1260258766118.1682\n",
      "Epoch: 44 cost=-1350922343546.8799\n",
      "Epoch: 45 cost=-1445866025898.3555\n",
      "Epoch: 46 cost=-1545220153314.2100\n",
      "Epoch: 47 cost=-1648883163106.2117\n",
      "Epoch: 48 cost=-1757113644363.4043\n",
      "Epoch: 49 cost=-1870022866251.4033\n",
      "Epoch: 50 cost=-1987512951111.6802\n",
      "Epoch: 51 cost=-2109995444291.0256\n",
      "Epoch: 52 cost=-2237495825232.9902\n",
      "Epoch: 53 cost=-2369789407455.4175\n",
      "Epoch: 54 cost=-2507371251332.1895\n",
      "Epoch: 55 cost=-2650101324066.4409\n",
      "Epoch: 56 cost=-2798156501840.9873\n",
      "Epoch: 57 cost=-2951734069940.5977\n",
      "Epoch: 58 cost=-3110546530750.8320\n",
      "Epoch: 59 cost=-3275144268945.2163\n",
      "Epoch: 60 cost=-3445447431648.3481\n",
      "Epoch: 61 cost=-3621453834962.3872\n",
      "Epoch: 62 cost=-3803562655565.2651\n",
      "Epoch: 63 cost=-3991480545741.7266\n",
      "Epoch: 64 cost=-4185467697233.9219\n",
      "Epoch: 65 cost=-4385824975570.3823\n",
      "Epoch: 66 cost=-4592492498482.2695\n",
      "Epoch: 67 cost=-4805237880079.8232\n",
      "Epoch: 68 cost=-5024895454174.4873\n",
      "Epoch: 69 cost=-5250875628406.2305\n",
      "Epoch: 70 cost=-5483650761955.1455\n",
      "Epoch: 71 cost=-5722865728821.0625\n",
      "Epoch: 72 cost=-5969265751013.9287\n",
      "Epoch: 73 cost=-6222496228728.0879\n",
      "Epoch: 74 cost=-6482975599076.0674\n",
      "Epoch: 75 cost=-6750498101895.9160\n",
      "Epoch: 76 cost=-7025367369526.9268\n",
      "Epoch: 77 cost=-7307409748250.9951\n",
      "Epoch: 78 cost=-7597051458474.3564\n",
      "Epoch: 79 cost=-7894015864876.6904\n",
      "Epoch: 80 cost=-8198783927344.4043\n",
      "Epoch: 81 cost=-8511325499317.5264\n",
      "Epoch: 82 cost=-8831833630310.3984\n",
      "Epoch: 83 cost=-9159996258385.9199\n",
      "Epoch: 84 cost=-9496428968196.6562\n",
      "Epoch: 85 cost=-9840951662048.3516\n",
      "Epoch: 86 cost=-10193737953622.5781\n",
      "Epoch: 87 cost=-10554570830583.6309\n",
      "Epoch: 88 cost=-10924085998804.2441\n",
      "Epoch: 89 cost=-11302273662678.1094\n",
      "Epoch: 90 cost=-11688720927293.4473\n",
      "Epoch: 91 cost=-12083711030186.3652\n"
     ]
    }
   ],
   "source": [
    "# Session - run and evaluate\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "sess.run(init)\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0.0\n",
    "    total_batch = int(n_samples/batch_size)\n",
    "    \n",
    "    #loop over all batches\n",
    "    for i in range(total_batch):\n",
    "        # grab the next batch for training the data and labels\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        # feed into the dictionary in order to optimize and minimize loss\n",
    "        _, c = sess.run([optimizer, cost], feed_dict={x:batch_x, y:batch_y})\n",
    "        \n",
    "        #compute avg loss\n",
    "        avg_cost += c / total_batch\n",
    "        \n",
    "    print(\"Epoch: {} cost={:.4f}\".format(epoch+1, avg_cost))\n",
    "    \n",
    "print(\"Model has completed {} Epochs of training\".format(training_epochs))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
